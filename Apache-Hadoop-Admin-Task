• Load DATA through pipeline S3 to EC2 


<property>
     <name>fs.s3n.awsAccessKeyId</name>
     <value>{AWS_ACCESS_KEY}</value>
    </property>

    <property>
     <name>fs.s3n.awsSecretAccessKey</name>
     <value>{AWS_SECRET_KEY}</value>
    </property>

s3n://datasetss/Datasets/purchases.txt

______________________________________________________________________________

DISTCP

hadoop distcp hdfs://domU-12-31-33-00-02-DF:9001/user/nutch/0070206153839-1998 s3://123:456@nutch/
_____________________________________________________________________________________________

Decommisioning

vi excludes
ip-172-31-30-159.eu-west-1.compute.internal

hdfs-site.xml

<property>
<name>dfs.hosts.exclude</name>
<value>/usr/local/hadoop/conf/excludes</value>
<final>true</final>
</property>

mapred-site.xml

<property>
<name>mapred.hosts.exclude</name>
<value>/usr/local/hadoop/conf/excludes</value>
<final>true</final>
</property>

hadoop dfsadmin -refreshNodes

hadoop mradmin -refreshNodes

hadoop dfsadmin -report
___________________________________________________________________________________________

Commissioning

vi includes
ip-172-31-30-159.eu-west-1.compute.intern

update the Nodes in slaves file

Remove the Nodes from exclude file

hdfs-site.xml

<property>
<name>dfs.hosts.include</name>
<value>/home/hadoop/includes</value>
<final>true</final>
</property>

mapred-site.xml

<property>
<name>mapred.hosts.include</name>
<value>/home/hadoop/includes</value>
<final>true</final>
</property>

start-balancer.sh

hadoop dfsadmin -report > report_date

______________________________________________________________________________________________________

• system file checker

hadoop fsck -location -block -size

hadoop fsck -

hadoop  fsck  / >  /usr/local/hadoop/reports/fsck_dated.log



___________________________________________________________________________
• Trash configuration 

nano core-site.xml

<property>
<name>fs.trash.interval</name>
<value>30</value>
<description>Number of minutes between trash checkpoints. If zero, the trash feature is disabled</description>
</property>

<property>
<name>fs.trash.checkpoint.interval</name>
<value>15</value>

</property>



hadoop fs -expunge

_____________________________________________________________________________

nano hdfs-site.xml

Block Size 

<property>
<name>dfs.block.size</name>
<value>134217728</value>
</property>

__________________________________________________________________________--

hadoop version

hadoop fs -ls /  ---------to check hadoop root

hadoop fs -du hdfs:/  -------------disk usage

hadoop fs -count hdfs:/ --------- file count

hadoop fsck /    ------------ file system health checker 

hadoop balancer  ---------Node balancing (will balance under and over replication)

hadoop fs -expunge      ---------- remove file from trash

hadoop fs -chmod 600 path

hadoop archive -archiveName smallfiles.har -p /user/ubuntu/smallfiles /user/ubuntu/

hadoop fs -ls 

hadoop fs -lsr smallfiles.har

hadoop fs -lsr har:///user/ubuntu/sachin.har
 
